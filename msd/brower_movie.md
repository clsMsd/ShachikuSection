# ブラウザでの動画再生

## コンテナとコーデック
ブラウザでの動画再生について述べる前に、前提知識としてコンテナとコーデックについて説明する。  
コンテナというのは文字通り箱のように動画・音声・その他メタデータなどの複数のデータを単一のファイルにまとめるフォーマットの規格であり、  
コーデックというのは実際に格納する映像や音声のデータの圧縮方法についての規格である。  

例えば MPEG-2 と言ったときに、動画コーデック(H.262/MPEG-2 Video) のことを指すのか、動画コンテナ(MPEG-2 TSまたはMPEG-2 PS)のことを  
指すのか文脈から適切に判断しないと「HLSってMPEG-2使ってるのかよwww 2020年にもなってMPEG-2使うとか効率悪すぎだろwww」などの勘違いが発生したりする。  

また、コーデックの名称で「H.264/AVC」や「H.265/HEVC」のようにスラッシュ区切りで2つの名称が併記されているのを  
見たことがあるかもしれないが、これら(スラッシュの前の名称と後の名称)は規格の策定団体の違いにより呼び分けられているだけで  
規格の中身は同一のものである。  
(何故別々の団体で同じ規格に別の名前を付けるのか……ｺﾚｶﾞﾜｶﾗﾅｲ)  

代表的な動画コンテナ
- AVI(Audio Video Interleave): 拡張子がaviのあれ。昔はWindowsで動画ファイルといえばこれという感じだったが最近ではあまり見ない。大昔に作られたのでチャプター機能や字幕が使えないなど機能が貧弱。
- WMV(Windows Media Video): AVIの後継としてMSが作ったコンテナ。コンテナと言いつつコーデックも内包していて，WMV9というコーデックの専用コンテナとなっている。
- MPEG-2 TS: 地デジなどテレビ放送でよく使われるコンテナ。後で述べるがHLSでも使われる。TSはTransportStreamの略
- MPEG-2 PS: DVD-Videoで使われるコンテナ。PSはProgramStreamaの略
- MOV(QuickTime File Format): Macでよく使われるコンテナフォーマット。拡張されていろいろなコンテナフォーマットの元祖になっている。
- ISO BMFF(ISO BaseMediaFileFormat, MPEG-4 Part12): 
- MP4(MPEG-4 Part14): MPEG-4規格の一部として制定されたコンテナフォーマット。体感的に一番よく使われている気がする。
- Ogg(ogv): Xiph.Orgという非営利団体が作ったコンテナフォーマット。権利関係の問題が無く自由に使える。映像以外にも音声やテキストのコンテナとしても使われており、単にOggファイルと言った場合は音声ファイルであることが多い(気がする)ので注意。動画ファイルであることを明示的に表す場合は拡張子を.ogvにする。
- FLV(Flash Video): Flashは死んだんだ いくら呼んでも帰っては来ないんだ もうあの時間は終わって、君も人生と向き合う時なんだ
- DivX(DivX Media Format): Stage6は死んだんだ いくら呼んでも帰っては来ないんだ もうあの時間は終わって、君も人生と向き合う時なんだ  
  (意味がわからない若者のために一応説明すると、Stage6というのはDivX Networkという会社がかつて運営していた動画サイトでyoutubeやニコニコに比べて高画質の動画が共有できたので深夜アニメが違法にアップロードされてアングラ系ネット掲示板の利用者に重宝された。2008年に閉鎖された)
- 3GPP: ガラケー時代によく使われていた。携帯動画変換君のあれ
- Matroska: 拡張子がmkvのあれ。いろいろなコーデックに対応している。Oggと同じくロイヤリティフリーのオープンフォーマット。
- WebM: Googleで開発されたロイヤリティフリーのコンテナフォーマット。youtubeの動画は基本全部これらしい

代表的な動画コーデック
- MPEG-1 Video: ビデオCDという幻のメディアで使われたコーデック。どうでもいいがセガサターンにはビデオCDの再生のための純正拡張カードがあった。
- H.262/MPEG-2 Video: 動画コーデックとしてのMPEG-2。地デジやDVD-Videoで使われている。
- H.263: 使われているところを見たことが無い、謎に包まれたコーデック。ちなみにMPEG-3という規格は策定中にMPEG-2に統合されたので存在しない。 
- MPEG-4 Visual: H.263と互換性があるとか無いとか出てきたがよくわからん。CravingExploreというソフトで
- H.264/MPEG-4 AVC: ブルーレイやワンセグをはじめとして多分一番広く使われているコーデック。画質が良い，有料だがH.265と比べて権利関係がカオスでない，エンコード/デコードが比較的楽などのメリットがある。
- H.265/HEVC: H.264の後継。H.264より圧縮率が高く画質が綺麗という長所があるが，エンコード/デコードが重い，パテントプールが4つあって権利関係が大変なことになっているなどの短所からH.264を置き換えるには至っていない
- H.266/VVC: H.265の後継。2020年中頃の規格完成を目標にしているらしいのだが結局完成したのか良くわからん←完成したらしい  
- VP6, VP7: On2テクノロジーという会社が作ったコーデック。Flash Video時代によく使われた。
- VP8: On2テクノロジーをGoogleが買収した後に作られたVP7の後継
- VP9: VP8の後継。オープンフォーマットであり画質が良く圧縮率も高い。YouTubeの動画は基本的にこれを使っているらしい。
- AV1: Googleを中心にしてH.265の権利関係に嫌気が差した企業たち(Google, Apple, Microsoft, Amazon, Facebook, IBM, Intel, Netflix など)が作ったロイヤリティフリーなコーデック。無料で使えて画質も綺麗で圧縮率も高いがエンコードにめっちゃ時間がかかるらしい
- Theora: Xiph.orgが作った動画コーデック。パテントフリー
- WMV9: WMVのためにMicrosoftが作ったコーデック。H.264とほぼ同等の画質らしい。
- VC-1: WMV9を規格化したもの。あまり知られていないがブルーレイに時々使われている。
- Motion JPEG: JPEG画像を集めただけのコーデック。仕組みがシンプルなのがメリットだがフレーム間予測をしないので当然圧縮率は低い。昔のデジカメの録画機能で動画を撮るとこれになることが多かった気がする。
- 無圧縮RGBA: 圧縮してないのでコーデックではないが便宜上ここに書く。各フレーム毎の各ピクセルの色情報をそのまま書いたフォーマット。  
  圧縮してないのでハチャメチャに大きいデータ量になるが、実はアルファチャンネルを扱える動画フォーマットというのが他にあまりないため、素材用のフォーマットとしてはよく使われるらしい。  
  MMDを始めたばかりの人がこれで動画出力してファイルサイズがハチャメチャなことになってビックリするというのは誰もが通る道だと思う。  

代表的な音声コーデック
- MP3(MPEG-1/2 Audio Layer-3)
- AAC
- Vorbis

など...

これらのコンテナとコーデックはなんでも自由に組み合わせられるというわけではない。  
例えばコンテナとしてWebMを使う場合はH.264, H.265等のMPEG系のコーデックが使えないという制限がある。  
逆にコンテナとしてMP4を使う場合はVP8, VP9等の非MPEG系のコーデックを使うこともできる。  
またMPEG-2 TS/PS が制定された時点ではH.264には対応していなかった(当時はH.264がまだ存在していなかったので)が，  
後にH.264の規格が策定されるとMPEG-2 TS/PSも規格が拡張されてH.264が扱えるようになった  
(一方でH.265についてはいまだ対応していない)。  
また規格としては許される組み合わせであっても、プレーヤーが対応していなくて再生できないという場合もある。  
この辺がガバガバだった10~15年位前では「同じavi形式の動画なのになぜか再生できるものとできないものがある」  
みたいなことがよくあったが、最近では mp4 + h264, mp4 + h265, WebM + VP9 などの定番の組み合わせが  
使われるようになったのと、プレーヤーがなんか色々対応してくれるようになったのでそういう事態に遭遇する機会は減っている気がする。  
<s>YouTubeやスマホの普及でファイル共有ソフトが下火になっただけという可能性もある</s>

ちなみにコーデックというのはCoder/Decoderの略であり、データのエンコード(符号化)/デコード(復号)を行うためのハードウェアやソフトウェア(つまり、規格ではなく実装)のことを指す場合がある。
(というかそっちの方が多いかもしれない)。  
この辺の感覚はプログラミング言語とその処理系の関係に若干近いかもしれない。  
(例えばC言語のようにちゃんとした仕様が定められていてその仕様に基づいた複数の実装が存在する言語の場合、仕様の名称と実装の名称は明確に区別される。
しかし、仕様が定められておらず、処理系の実装も1つしか無いようなマイナー言語の場合、存在する実装の動作こそが仕様であり、仕様の名称と実装の名称を区別する意味が薄い。
同じように圧縮フォーマットも圧縮/展開を行うソフトウェアが1つしかなければ「圧縮を行うソフトウェアの名称」と「圧縮フォーマットの名称」が同じであっても余り問題が無いが、
同じ圧縮フォーマットに対して圧縮/展開を行うソフトウェアが複数ある場合は区別する必要が生まれてくる。)  

## とりあえず再生する
昔はブラウザで動画を再生するにはFlash, Quicktime, RealtimePlayerなどのプラグインを使う必要があった  
(インターネット老人会の昔話)が、今ではブラウザがネイティブで動画に対応しているので画像と同じように  
htmlにタグを埋め込むだけでよい。  

```html
<video src="sample.mp4">
</video>
```

ブラウザによって対応しているコンテナ・コーデックが異なるので、動画を配信する前にどのコンテナ・コーデックを選ぶべきか考える必要がある。  
https://developer.mozilla.org/en-US/docs/Web/Media/Formats/Video_codecs  
https://www.chromium.org/audio-video  

## ライブストリーミング
とりあえずブラウザで動画を再生するだけなら上のような方法で良いのだが，これだけでは以下のような実用上不便な点が多々ある。  
- 再生したい時点までの動画のダウンロードが完了していないと，動画を途中から再生できない 
- 通信環境に応じて低画質・低ビットレートの動画や高画質・高ビットレートの動画を選択するということができない(AdaptiveBitRates)
- 予め録画が完了した動画ではなく，撮影中の動画をライブ配信するということができない

これらの問題点を解決するために作られたのが、ライブストリーミングという技術である。  
これはどういうものかというと、数秒単位でぶつ切りにした動画ファイル(これをメディアセグメントファイルという)と、  
各動画ファイルについての情報が書かれたファイル(これをインデックスファイルまたはプレイリストという)の2種類のファイルを用意し、  
動画を途中から再生する場合はインデックスファイルから再生したい時点の動画ファイルの情報を読み取り，  
必要な動画ファイルをダウンロードしてそこから再生するというものである。  

ライブストリーミングの規格には Microsoft が開発した SmoothStreaming、Apple が開発した　HLS、  
Adobe が開発した HTTP Dynamic Streaming、MPEG が開発した MPEG-DASH などがあるが、  
今現在良く用いられるのは MPEG-DASH と HLS である。  
特に Apple製品を対象とする場合はほぼ確実にHLS対応が必須なので、 

<!-- ### HLS(HTTP Live Streaming)
Appleの作ったストリーミング技術。

### mpeg-dash
MPEG(Moving Picture Experts Group)が開発し，ISO/IECの国際標準規格として策定されたオープンなライブストリーミング技術。  
もともとはFlashで使われていたAdobeのHDSとSilverlightで使われていたMicrosoftのSmoothStreamingという2つのライブストリーミング技術が前身となっているらしい。  

基本的な仕組みはHLSと同じだが，HLSと異なる点として以下が挙げられる。
- オープンな規格なのでApple 1社の意向に左右されない
- インデックスファイルにXMLを使うので，複雑な制御が可能など高機能 (その代わり人間が読むのは辛い)
- 字幕が高機能
- マルチDRM対応しやすい
- Apple製品ではほとんどサポートされない。  
  iOS Safariでは再生できないし，AppStoreでmpeg-dashを使ったアプリをリリースするとAppleからリジェクトされる -->

AppStoreのガイドライン
> 2.5.7 Video streaming content over a cellular network longer than 10 minutes must use HTTP Live Streaming and include a baseline 192 kbps HTTP Live stream.
> (cited from https://developer.apple.com/app-store/review/guidelines/)

## HLSでストリーミング再生する

### サーバー側の準備
Webサーバー側で必要な準備は少なく，やることはインデックスファイル(.m3u8)とメディアセグメントファイル(.ts)を用意して、
各ファイルのMINEタイプの関連付けを行うだけである(MINEタイプの関連付けは普通のサーバーを使えば自動で行ってくれる)。  

まずはファイルの生成のためにffmpegをインストールしてパスを通しておく。  
ffmpegがインストールできたら下のコマンドで.tsファイルと.m3u8ファイルを生成する。
```bash
ffmpeg -i "入力ファイル名" -c:v copy -c:a copy -f hls -hls_time 9 -hls_playlist_type vod -hls_segment_filename "video%3d.ts" video.m3u8
```
あとは生成されたファイルをサーバーで公開すれば良い。

#### インデックスファイル(m3u8プレイリスト)
インデックスファイルの中身は次のようになっている。
```
#EXTM3U
#EXT-X-VERSION:3
#EXT-X-TARGETDURATION:9
#EXT-X-MEDIA-SEQUENCE:0
#EXT-X-PLAYLIST-TYPE:VOD
#EXTINF:9.259256,
video000.ts
#EXTINF:9.009000,
video001.ts
#EXTINF:9.009000,
video002.ts
#EXTINF:9.009000,
video003.ts
...
#EXTINF:6.742311,
video013.ts
#EXT-X-ENDLIST
```
各タグの意味
- `EXTM3U`: 拡張M3U形式であることを表すヘッダ
- `EXT-X-PLAYLIST-TYPE`: プレイリストの可変性についてのヘッダ。`VOD`又は`EVENT`の2種類の値を取りうる。  
   `VOD`の場合はプレイリストは不変である。`EVENT`の場合はプレイリストの末尾にメディアセグメントを追加することができる(ライブ配信などで使われる)。  
- `EXT-X-TARGETDURATION`: 各メディアセグメントファイルの最大の長さを表す
- `EXTINF`: 次の行に記述されるメディアセグメントファイルの長さを表す
- `EXT-X-ENDLIST`: その行がプレイリストの終端であることを表す



### ブラウザ側の準備
ブラウザ側の準備はSafariのようにネイティブでHLSを再生できるブラウザと、それ以外のブラウザで大きく異なる。  

Safari の場合は普通の動画と同じように`video`タグの`src`属性に m3u8プレイリストのURLを指定すればよい。  

Safari以外のブラウザは再生のためにライブラリを使用する必要がある。  
HLSを再生できるライブラリはいくつかあるが、今回は HLS.js を使う。

```html
<html>
  <head></head>
  <body>
    <video style="width: 1200px; height: 720px;" id="video" controls>
    </video>
    <script src="https://cdn.jsdelivr.net/npm/hls.js@latest"></script>
    <script>
      const video = document.getElementById("video")
      const hls = new Hls()
      hls.attachMedia(video)
      hls.loadSource("/video.m3u8")
    </script>
  </body>
</html>
```
## 参考資料
https://qiita.com/okumurakengo/items/5627326ee833a3a5ea03
https://www.jsa.or.jp/datas/media/10000/md_2471.pdf
